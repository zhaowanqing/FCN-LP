{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e947c3-3e0c-4fef-aee7-73c3c851af1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import clip\n",
    "from torch.utils.data import Dataset, DataLoader, BatchSampler\n",
    "from tqdm.notebook import tqdm\n",
    "import nltk, re, string\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\" # If using GPU then use mixed precision training.\n",
    "%matplotlib inline\n",
    "dataset_name = 'twitter' # twitter or weibo or pheme\n",
    "saveCSV = True\n",
    "BATCH_SIZE = 32\n",
    "Threshold = 0.95  #Similarity Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea494803-efa8-4528-92f1-ccffaa087f4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c60f5e6-6c03-4e78-9a70-ba19b324e0d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc727dc2-49b6-4139-959d-f8f2a7d924e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess_text\n",
    "def preprocess_text(text):\n",
    "    # Remove extra whitespaces\n",
    "    text = text.strip()\n",
    "\n",
    "    #text = re.sub(u\"[:,.；|-“”——_/nbsp+&;@、《》～（）())#O！：【】]\", \"\", text)\n",
    "    #Remove html tags\n",
    "    text = re.sub(re.compile('<.*?>'), ' ', text)\n",
    "\n",
    "    #Remove unwanted characters\n",
    "    text = word_tokenize(text)\n",
    "    text = ' '.join(word for word in text if word.isalpha() or word.isnumeric() or word.isalnum())\n",
    "    return text\n",
    "\n",
    "def preprocess_event(text):\n",
    "    text = text.split('_')[0]\n",
    "    return text\n",
    "if dataset_name == 'weibo':\n",
    "    df = pd.read_csv('dataset/weibo/weibo_train.csv')\n",
    "    df_test = pd.read_csv('dataset/weibo/weibo_test.csv')\n",
    "    df['event'] = df['image_id']\n",
    "    df_test['event'] = df_test['image_id']\n",
    "    for i in  range(0, len(df['event'])):\n",
    "        df['event'][i] = 1 \n",
    "    for i in  range(0, len(df_test['event'])):\n",
    "        df_test['event'][i] = 1 \n",
    "    IMG_ROOT_train = \"dataset/weibo/images\"\n",
    "    IMG_ROOT_test = \"dataset/weibo/images\"\n",
    "if dataset_name == 'twitter':\n",
    "    df= pd.read_csv('twitter/train_posts_clean.csv')\n",
    "    df_test = pd.read_csv('twitter/test_posts.csv')\n",
    "    df['event'] = df['image_id']\n",
    "    for i in  range(0, len(df['label'])):\n",
    "        df['label'][i] = 1 if df['label'][i] == 'real' else 0\n",
    "    df.event = np.array([preprocess_event(text) for text in df.event])\n",
    "    df_test['event'] = df_test['image_id']\n",
    "    for i in  range(0, len(df_test['label'])):\n",
    "        df_test['label'][i] = 1 if df_test['label'][i] == 'real' else 0\n",
    "    df_test.event = np.array([preprocess_event(text) for text in df_test.event])\n",
    "    IMG_ROOT_train = \"dataset/twitter/twitter_cleaned/images_train\"\n",
    "    IMG_ROOT_test = \"dataset/twitter/twitter_cleaned/images_test\"\n",
    "if dataset_name == 'pheme':\n",
    "    df = pd.read_csv('dataset/pheme/pheme_train.csv')\n",
    "    df_test = pd.read_csv('dataset/pheme/pheme_test.csv')\n",
    "    IMG_ROOT_train = \"dataset/pheme/pheme_image/images\"\n",
    "    IMG_ROOT_test = \"dataset/pheme/pheme_image/images\" \n",
    "    \n",
    "df.rename(columns={'post_text': 'text'}, inplace=True)\n",
    "df.text = np.array([preprocess_text(text) for text in df.text])\n",
    "df_test.rename(columns={'post_text': 'text'}, inplace=True)\n",
    "df_test.text = np.array([preprocess_text(text) for text in df_test.text])\n",
    "if saveCSV and dataset_name == 'weibo':\n",
    "    df.to_csv('dataset/weibo/dataforGCN_train.csv',index=False)\n",
    "    df_test.to_csv('dataset/weibo/dataforGCN_test.csv',index=False)\n",
    "if saveCSV and dataset_name == 'twitter':\n",
    "    df.to_csv('dataset/twitter/dataforGCN_train.csv',index=False)\n",
    "    df_test.to_csv('dataset/twitter/dataforGCN_test.csv',index=False)\n",
    "if saveCSV and dataset_name == 'pheme':\n",
    "    df.to_csv('dataset/pheme/dataforGCN_train.csv',index=False)\n",
    "    df_test.to_csv('dataset/pheme/dataforGCN_test.csv',index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7bf116-7ef2-4ab2-8cc4-cc681084bd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create database    \n",
    "class image_caption_dataset(Dataset):\n",
    "    def __init__(self, df, IMG_ROOT,  name=\"twitter\"):\n",
    "        self.dataset_name = name\n",
    "        self.img_root = IMG_ROOT\n",
    "        if name == \"twitter\":\n",
    "            self.images = df[\"image_id\"].tolist()\n",
    "            self.caption = df[\"text\"].tolist()\n",
    "            self.label = df[\"label\"].tolist()\n",
    "            self.event = df[\"event\"].tolist()\n",
    "        elif name == \"weibo\":\n",
    "            self.images = df[\"image_id\"].tolist()\n",
    "            self.caption = df[\"text\"].tolist()\n",
    "            self.label = df[\"label\"].tolist()\n",
    "            self.event = df[\"event\"].tolist()\n",
    "        elif name == \"pheme\":\n",
    "            self.images = df[\"imgnum\"].tolist()\n",
    "            self.caption = df[\"text\"].tolist()\n",
    "            self.label = df[\"label\"].tolist()\n",
    "            self.event = df[\"event\"].tolist()\n",
    "        # self.caption=clip.tokenize(caption) \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.caption)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.dataset_name == \"twitter\":\n",
    "            images = preprocess(Image.open(self.img_root+'/'+self.images[idx]+'.jpg')) #preprocess from clip.load\n",
    "        elif self.dataset_name == \"weibo\":\n",
    "            images = preprocess(Image.open(self.img_root+'/'+self.images[idx])) #preprocess from clip.load\n",
    "        elif self.dataset_name == \"pheme\":\n",
    "            images = preprocess(Image.open(self.img_root+'/'+str(self.images[idx])+'.jpg')) #preprocess from clip.load\n",
    "        caption = self.caption[idx]\n",
    "        label = self.label[idx]\n",
    "        event = self.event[idx]\n",
    "        return images, caption, label, event, idx\n",
    "    \n",
    "dataset = image_caption_dataset(df, IMG_ROOT_train, dataset_name)\n",
    "dataset_test = image_caption_dataset(df_test, IMG_ROOT_test, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1301718-74d6-4001-b29d-a5ea51e29fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset including image and text embedding\n",
    "clip_model, preprocess = clip.load(\"ViT-B/32\",device=device,jit=False) #Must set jit=False for training\n",
    "data_dataloader = DataLoader(dataset, BATCH_SIZE, shuffle=False)\n",
    "pbar = tqdm(data_dataloader, leave=False)\n",
    "ALLimage_embeds = []\n",
    "ALLtext_embeds = []\n",
    "ALLlabels = []\n",
    "ALLids = []\n",
    "ALLevents = []\n",
    "for batch in pbar:\n",
    "        images, texts, labels, events, idxs = batch\n",
    "        images = images.to(device)\n",
    "        texts = clip.tokenize(texts,truncate=True).to(device)\n",
    "        with torch.no_grad():\n",
    "            image_features = clip_model.encode_image(images).float()\n",
    "            text_features = clip_model.encode_text(texts).float()\n",
    "        ALLimage_embeds.append(image_features)\n",
    "        ALLtext_embeds.append(text_features)\n",
    "        ALLlabels.extend(list(labels))\n",
    "        ALLevents.extend(list(events))\n",
    "        ALLids.append(idxs)\n",
    "ALLimage_embeds_train = torch.cat(ALLimage_embeds, dim=0)\n",
    "ALLtext_embeds_train = torch.cat(ALLtext_embeds, dim=0)\n",
    "ALLids = torch.cat(ALLids, dim=0)\n",
    "#print(predicted_class = probs.argmax(-1).item())\n",
    "#load dataset_test including image and text embedding\n",
    "\n",
    "data_dataloader = DataLoader(dataset_test, BATCH_SIZE, shuffle=False)\n",
    "pbar = tqdm(data_dataloader, leave=False)\n",
    "ALLimage_embeds = []\n",
    "ALLtext_embeds = []\n",
    "ALLlabels = []\n",
    "ALLids = []\n",
    "ALLevents = []\n",
    "for batch in pbar:\n",
    "        images, texts, labels, events, idxs = batch\n",
    "        images = images.to(device)\n",
    "        texts = clip.tokenize(texts,truncate=True).to(device)\n",
    "        with torch.no_grad():\n",
    "            image_features = clip_model.encode_image(images).float()\n",
    "            text_features = clip_model.encode_text(texts).float()\n",
    "        ALLimage_embeds.append(image_features)\n",
    "        ALLtext_embeds.append(text_features)\n",
    "        ALLlabels.extend(list(labels))\n",
    "        ALLevents.extend(list(events))\n",
    "        ALLids.append(idxs)\n",
    "ALLimage_embeds_test = torch.cat(ALLimage_embeds, dim=0)\n",
    "ALLtext_embeds_test = torch.cat(ALLtext_embeds, dim=0)\n",
    "ALLids = torch.cat(ALLids, dim=0)\n",
    "#print(predicted_class = probs.argmax(-1).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3df548-a6ea-4edd-8e26-828e23b872fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Similarity and Tweet Graph Construction\n",
    "def calculate_cosine_similarity_matrix(h_emb, eps=1e-5):\n",
    "    # h_emb (N, M)\n",
    "    # normalize\n",
    "    a_n = h_emb.norm(dim=1).unsqueeze(1)\n",
    "    a_norm = h_emb / torch.max(a_n, eps * torch.ones_like(a_n))\n",
    "    # cosine similarity matrix\n",
    "    sim_matrix = torch.einsum('bc,cd->bd', a_norm, a_norm.transpose(0,1))\n",
    "    return sim_matrix\n",
    "ALLCAT_embeds_train = torch.cat((ALLimage_embeds_train, ALLtext_embeds_train), 1)\n",
    "ALLCAT_embeds_test = torch.cat((ALLimage_embeds_test, ALLtext_embeds_test), 1)\n",
    "ALLCAT_embeds = torch.cat((ALLCAT_embeds_train, ALLCAT_embeds_test), 0)\n",
    "ALLimage_embeds = torch.cat((ALLimage_embeds_train, ALLimage_embeds_test), 0)\n",
    "ALLtext_embeds = torch.cat((ALLtext_embeds_train, ALLtext_embeds_test), 0)\n",
    "\n",
    "ALLCAT_embeds /= ALLCAT_embeds.norm(dim=-1, keepdim=True)\n",
    "ALLimage_embeds /= ALLimage_embeds.norm(dim=-1, keepdim=True)\n",
    "ALLtext_embeds /= ALLtext_embeds.norm(dim=-1, keepdim=True)\n",
    "\n",
    "ALLCAT_similarity = (ALLCAT_embeds @ ALLCAT_embeds.T)\n",
    "i2t_similarity = (ALLimage_embeds @ ALLtext_embeds.T)\n",
    "t2i_similarity = (ALLtext_embeds @ ALLimage_embeds.T)\n",
    "i2i_similarity = (ALLimage_embeds @ ALLimage_embeds.T)\n",
    "t2t_similarity = (ALLtext_embeds @ ALLtext_embeds.T)\n",
    "\n",
    "result_tensor = torch.zeros_like(ALLCAT_similarity)\n",
    "result_tensor[(i2t_similarity > Threshold) | (t2t_similarity > Threshold)] = 2\n",
    "result_tensor[(t2i_similarity > Threshold) | (i2i_similarity > Threshold)] = 3\n",
    "result_tensor[(t2t_similarity > Threshold) & (i2i_similarity > Threshold)] = 1\n",
    "result_tensor[(t2i_similarity > Threshold) & (i2t_similarity > Threshold)] = 1\n",
    "result_tensor[ALLCAT_similarity > Threshold] = 1\n",
    "edge = result_tensor\n",
    "edge_sparse = edge.to_sparse()\n",
    "torch.save(edge_sparse, 'dataset/'+dataset_name+'/TweetGraph.pt')\n",
    "torch.save(ALLCAT_embeds, 'dataset/'+dataset_name+'/TweetEmbeds.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
